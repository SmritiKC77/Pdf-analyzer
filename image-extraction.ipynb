{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T03:01:42.091275Z",
     "iopub.status.busy": "2025-03-04T03:01:42.090975Z",
     "iopub.status.idle": "2025-03-04T03:01:51.782814Z",
     "shell.execute_reply": "2025-03-04T03:01:51.781430Z",
     "shell.execute_reply.started": "2025-03-04T03:01:42.091245Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyMuPDF\n",
      "  Downloading pymupdf-1.25.3-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.2.4)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
      "Collecting python-docx\n",
      "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.57.4)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.25.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from nltk) (1.17.0)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (5.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.11.0a2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.4.2)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.36.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2024.12.12)\n",
      "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (24.2)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (0.4)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy) (2.4.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.29.0)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy) (2024.2.0)\n",
      "Downloading pymupdf-1.25.3-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: python-docx, PyMuPDF\n",
      "Successfully installed PyMuPDF-1.25.3 python-docx-1.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install PyMuPDF nltk  Pillow python-docx openai  scikit-image scipy numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T03:01:51.784671Z",
     "iopub.status.busy": "2025-03-04T03:01:51.784285Z",
     "iopub.status.idle": "2025-03-04T03:02:05.959976Z",
     "shell.execute_reply": "2025-03-04T03:02:05.958606Z",
     "shell.execute_reply.started": "2025-03-04T03:01:51.784637Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-5.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (22.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Downloading fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting gradio-client==1.7.2 (from gradio)\n",
      "  Downloading gradio_client-1.7.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting groovy~=0.1 (from gradio)\n",
      "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.29.0)\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
      "Collecting markupsafe~=2.0 (from gradio)\n",
      "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.12)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.3)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.11.0a2)\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
      "Collecting ruff>=0.9.3 (from gradio)\n",
      "  Downloading ruff-0.9.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
      "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Downloading starlette-0.46.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.15.1)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.7.2->gradio) (2024.12.0)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.7.2->gradio) (14.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.17.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.0->gradio) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.0->gradio) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.0->gradio) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.0->gradio) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.0->gradio) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.0->gradio) (2.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.29.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0,>=1.0->gradio) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0,>=1.0->gradio) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.0->gradio) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<3.0,>=1.0->gradio) (2024.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<3.0,>=1.0->gradio) (2024.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Downloading gradio-5.20.0-py3-none-any.whl (62.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading gradio_client-1.7.2-py3-none-any.whl (322 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.1/322.1 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading ruff-0.9.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading starlette-0.46.0-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
      "Installing collected packages: uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, groovy, ffmpy, starlette, safehttpx, gradio-client, fastapi, gradio\n",
      "  Attempting uninstall: markupsafe\n",
      "    Found existing installation: MarkupSafe 3.0.2\n",
      "    Uninstalling MarkupSafe-3.0.2:\n",
      "      Successfully uninstalled MarkupSafe-3.0.2\n",
      "Successfully installed fastapi-0.115.11 ffmpy-0.5.0 gradio-5.20.0 gradio-client-1.7.2 groovy-0.1.2 markupsafe-2.1.5 python-multipart-0.0.20 ruff-0.9.9 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.0 tomlkit-0.13.2 uvicorn-0.34.0\n"
     ]
    }
   ],
   "source": [
    "!pip install  gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T03:02:05.961502Z",
     "iopub.status.busy": "2025-03-04T03:02:05.961169Z",
     "iopub.status.idle": "2025-03-04T03:02:11.882505Z",
     "shell.execute_reply": "2025-03-04T03:02:11.881433Z",
     "shell.execute_reply.started": "2025-03-04T03:02:05.961471Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.20.0\n"
     ]
    }
   ],
   "source": [
    "import gradio\n",
    "print(gradio.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-04T03:02:15.569280Z",
     "iopub.status.idle": "2025-03-04T03:02:15.569614Z",
     "shell.execute_reply": "2025-03-04T03:02:15.569475Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import fitz\n",
    "import re\n",
    "import nltk\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import requests\n",
    "import base64\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from docx import Document\n",
    "from docx.shared import Pt, Inches\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "\n",
    "\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "\n",
    "openrouter_api_key = \"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\"\n",
    "qwen_api_key = \"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\" \n",
    "\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=openrouter_api_key,\n",
    ")\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extract text from a PDF file\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    \n",
    "    for page_num, page in enumerate(doc):\n",
    "        # Extract text\n",
    "        page_text = page.get_text(\"text\")\n",
    "        page_text = re.sub(r'\\s+', ' ', page_text)  # Normalize spaces\n",
    "        text += page_text.strip() + \"\\n\\n\"\n",
    "                \n",
    "    return text.strip()\n",
    "\n",
    "def load_figures_from_folder(figures_folder):\n",
    "    \"\"\"Load figures from a folder\"\"\"\n",
    "    figures = []\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(figures_folder):\n",
    "        print(f\"Figures folder not found: {figures_folder}\")\n",
    "        return figures\n",
    "    \n",
    "  \n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff']\n",
    "    image_files = [f for f in os.listdir(figures_folder) \n",
    "                  if os.path.isfile(os.path.join(figures_folder, f)) and \n",
    "                  any(f.lower().endswith(ext) for ext in image_extensions)]\n",
    "    \n",
    "    \n",
    "    for img_file in image_files:\n",
    "        try:\n",
    "            img_path = os.path.join(figures_folder, img_file)\n",
    "            image = Image.open(img_path)\n",
    "            \n",
    "            \n",
    "            filename = os.path.splitext(img_file)[0]\n",
    "            caption = \"\"\n",
    "            \n",
    "            \n",
    "            fig_match = re.search(r'(figure|fig)[_\\-\\s]*(\\d+)[_\\-\\s]*(.*)', filename, re.IGNORECASE)\n",
    "            if fig_match:\n",
    "                fig_num = fig_match.group(2)\n",
    "                fig_caption = fig_match.group(3).replace('_', ' ').replace('-', ' ')\n",
    "                caption = f\"Figure {fig_num}: {fig_caption}\"\n",
    "            \n",
    "            \n",
    "            figures.append({\n",
    "                'image': image,\n",
    "                'filename': img_file,\n",
    "                'is_figure': True, \n",
    "                'caption': caption,\n",
    "                'page': 0  \n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_file}: {e}\")\n",
    "    \n",
    "    print(f\"Loaded {len(figures)} figures from folder\")\n",
    "    return figures\n",
    "\n",
    "def analyze_image_with_qwen(image, context=\"\"):\n",
    "    \"\"\"Use Qwen VL through OpenRouter to analyze an image\"\"\"\n",
    "    \n",
    "    buffered = BytesIO()\n",
    "    image.save(buffered, format=\"PNG\")\n",
    "    img_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "    \n",
    "    \n",
    "    if context:\n",
    "        prompt = f\"Analyze this figure from a textbook and explain its significance. Context: {context}\"\n",
    "    else:\n",
    "        prompt = \"Describe this figure from a textbook and explain what it represents in educational context.\"\n",
    "    \n",
    "    \n",
    "    openai_client = OpenAI(\n",
    "        base_url=\"https://openrouter.ai/api/v1\",\n",
    "        api_key=qwen_api_key,\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        completion = openai_client.chat.completions.create(\n",
    "            model=\"qwen/qwen-vl-plus:free\",  \n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/png;base64,{img_base64}\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        return completion.choices[0].message.content\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in Qwen VL API call: {e}\")\n",
    "        # Fallback description if the API call fails\n",
    "        return \"A diagram from the textbook.\"\n",
    "\n",
    "def clean_text(text, for_qa=False):\n",
    "    \"\"\"\n",
    "    Clean text with different patterns based on usage (summary or Q&A)\n",
    "    \"\"\"\n",
    "    if for_qa:\n",
    "        \n",
    "        text = re.sub(r'Activity\\s+\\d+\\.\\d+.*?(\\n|$)', '', text, flags=re.DOTALL)\n",
    "        text = re.sub(r'Figure\\s+\\d+\\.\\d+.*?\\n', '', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\b\\d{4}-\\d{2}\\b', '', text)\n",
    "        text = re.sub(r'\\n+', '\\n', text).strip()\n",
    "    else:\n",
    "        \n",
    "        text = re.sub(r'Activity\\s+\\d+\\.\\d+.*?(\\n|$)', '', text, flags=re.DOTALL)\n",
    "        text = re.sub(r'Q\\s?U\\s?E\\s?S\\s?T\\s?I\\s?O\\s?N\\s?S[\\s\\S]*?(\\n|$)', '', text, flags=re.DOTALL)\n",
    "        text = re.sub(r'Figure\\s+\\d+\\.\\d+.*?\\n', '', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\b\\d{4}-\\d{2}\\b', '', text)\n",
    "        text = re.sub(r'\\n+', '\\n', text).strip()\n",
    "\n",
    "    \n",
    "    text = re.sub(r'\\\\\\((.*?)\\\\\\)', lambda m: m.group(1).replace('\\\\', '').replace('_', ''), text)\n",
    "    text = re.sub(r'\\\\\\[(.*?)\\\\\\]', lambda m: m.group(1).replace('\\\\', '').replace('_', ''), text)\n",
    "    text = re.sub(r'\\\\text\\{(.*?)\\}', r'\\1', text) \n",
    "    text = re.sub(r'\\\\left\\((.*?)\\\\right\\)', r'(\\1)', text) \n",
    "    text = re.sub(r'\\\\rightarrow', r'→', text)  \n",
    "    text = re.sub(r'_\\{(.*?)\\}', r'_\\1', text)  \n",
    "    text = re.sub(r'\\^\\{(.*?)\\}', r'^\\1', text)  \n",
    "    \n",
    "    return text\n",
    "\n",
    "def extract_chapters(text, for_qa=False):\n",
    "    chapter_pattern = r\"(\\d+)\\s+CHAPTER([\\s\\S]*?)(?=\\d+\\s+CHAPTER|\\Z)\"\n",
    "    matches = re.findall(chapter_pattern, text, re.DOTALL)\n",
    "    \n",
    "    chapter_dict = {}\n",
    "    for number, content in matches:\n",
    "        chapter_dict[number] = clean_text(content, for_qa=for_qa)\n",
    "    \n",
    "    return chapter_dict\n",
    "\n",
    "def split_text_into_chunks(text, max_tokens=1000):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    chunks, current_chunk, current_length = [], [], 0\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        sentence_length = len(sentence.split())\n",
    "        if current_length + sentence_length > max_tokens:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk, current_length = [sentence], sentence_length\n",
    "        else:\n",
    "            current_chunk.append(sentence)\n",
    "            current_length += sentence_length\n",
    "    \n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "    return chunks\n",
    "\n",
    "def summarize_text(text):\n",
    "    try:\n",
    "        prompt = \"\"\"\n",
    "        Create a structured academic summary following these guidelines:\n",
    "        1. Start with key concepts and fundamental principles\n",
    "        2. Present main topics in a logical sequence\n",
    "        3. Include important definitions and explanations\n",
    "        4. Highlight significant examples and applications\n",
    "        5. Use clear, academic language\n",
    "        6. Avoid any personal thoughts or meta-commentary\n",
    "        7. Keep a formal, educational tone throughout\n",
    "        8. Format main topics in **bold** using Markdown syntax\n",
    "        9. Write all equations in plain text format (like \"2H2 + O2 → 2H2O\") not LaTeX format\n",
    "        \n",
    "        The summary should be suitable for a textbook chapter and avoid any informal language or thinking process phrases.\n",
    "        \"\"\"\n",
    "        \n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"deepseek/deepseek-r1:free\",\n",
    "            messages=[{\n",
    "                \"role\": \"user\", \n",
    "                \"content\": f\"{prompt}\\n\\nContent to summarize: {text}\"\n",
    "            }],\n",
    "            temperature=0.3\n",
    "        )\n",
    "        \n",
    "        summary = completion.choices[0].message.content.strip()\n",
    "        \n",
    "        \n",
    "        cleanup_patterns = [\n",
    "            (r'^(In this chapter|This chapter|Let me|I will).*?[.]\\s*', ''),\n",
    "            (r'(The answer is|This means that|Thus|Therefore|Hence|So|To summarize|In conclusion)[,:](.*?)$', r'\\2'),\n",
    "            (r'I (need to|will|should|can).*?[.!?]\\s*', ''),\n",
    "            (r'Let\\'s.*?[.!?]\\s*', ''),\n",
    "            (r'Based on.*?[.!?]\\s*', ''),\n",
    "            (r'Looking at.*?[.!?]\\s*', ''),\n",
    "            (r'First,|Second,|Third,|Finally,', '')\n",
    "        ]\n",
    "        \n",
    "        for pattern, replacement in cleanup_patterns:\n",
    "            summary = re.sub(pattern, replacement, summary, flags=re.IGNORECASE)\n",
    "            \n",
    "        return summary.strip()\n",
    "    except Exception as e:\n",
    "        return f\"Summarization Error: {e}\"\n",
    "\n",
    "def summarize_chapter(number, content, chapter_images=None):\n",
    "    if not content.strip():\n",
    "        return f\"**CHAPTER {number}**\\n\\nNo content available for summary.\", []\n",
    "    \n",
    "    chunks = split_text_into_chunks(content, max_tokens=2000)\n",
    "    chunk_summaries = []\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        summary = summarize_text(chunk)\n",
    "        if summary and not summary.startswith(\"Summarization Error\"):\n",
    "            chunk_summaries.append(summary)\n",
    "    \n",
    "    if len(chunk_summaries) > 1:\n",
    "        final_summary_prompt = \"\"\"\n",
    "        Create a comprehensive 3-page chapter summary that:\n",
    "        1. Begins with an overview of main concepts\n",
    "        2. Presents topics in a clear, logical order\n",
    "        3. Explains key theories and principles\n",
    "        4. Includes relevant examples and applications\n",
    "        5. Connects related concepts\n",
    "        6. Maintains academic language throughout\n",
    "        7. Avoids repetition and meta-commentary\n",
    "\n",
    "        Format as clear paragraphs with proper transitions.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"deepseek/deepseek-r1:free\",\n",
    "                messages=[{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"{final_summary_prompt}\\n\\nContent to summarize: {' '.join(chunk_summaries)}\"\n",
    "                }],\n",
    "                temperature=0.3\n",
    "            )\n",
    "            final_summary = completion.choices[0].message.content.strip()\n",
    "        except Exception:\n",
    "            final_summary = \"\\n\\n\".join(chunk_summaries)\n",
    "    else:\n",
    "        final_summary = chunk_summaries[0] if chunk_summaries else \"No summary available.\"\n",
    "    \n",
    "    \n",
    "    processed_images = []\n",
    "    if chapter_images and len(chapter_images) > 0:\n",
    "        \n",
    "        filtered_images = [img for img in chapter_images if img['is_figure']]\n",
    "        if not filtered_images:\n",
    "            filtered_images = chapter_images[:min(3, len(chapter_images))]\n",
    "        \n",
    "        for img_data in filtered_images[:3]:  \n",
    "            try:\n",
    "                \n",
    "                description = analyze_image_with_qwen(img_data['image'], content[:1000])\n",
    "                \n",
    "                \n",
    "                if img_data['caption']:\n",
    "                    full_caption = f\"{img_data['caption']} - {description}\"\n",
    "                else:\n",
    "                    full_caption = description\n",
    "                \n",
    "                processed_images.append({\n",
    "                    'image': img_data['image'],\n",
    "                    'caption': full_caption\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image for chapter {number}: {e}\")\n",
    "    \n",
    "    return f\"**CHAPTER {number}**\\n\\n{final_summary}\", processed_images\n",
    "\n",
    "\n",
    "def generate_sample_questions(chapter_text, chapter_images=None):\n",
    "    \n",
    "    image_context = \"\"\n",
    "    if chapter_images and len(chapter_images) > 0:\n",
    "        image_descriptions = [f\"Image {i+1}: {img['caption']}\" for i, img in enumerate(chapter_images)]\n",
    "        image_context = \"The chapter contains the following images:\\n\" + \"\\n\".join(image_descriptions)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Generate exactly 15 educational questions based on the content with the following distribution:\n",
    "    \n",
    "    - 3 Multiple Choice Questions (MCQs) with options (A, B, C, D) and correct answers:\n",
    "      * 1 MCQ that references one of the images\n",
    "      * 2 MCQs based on text content\n",
    "    \n",
    "    - 5 Short Answer questions (2-3 marks):\n",
    "      * 1 Short Answer question that references one of the images\n",
    "      * 4 Short Answer questions based on text content\n",
    "    \n",
    "    - 5 Long Answer questions (5 marks):\n",
    "      * 1 Long Answer question that references one of the images\n",
    "      * 4 Long Answer questions based on text content\n",
    "    \n",
    "    - 2 Case-Based questions:\n",
    "      * 1 Case-Based question that references one of the images\n",
    "      * 1 Case-Based question based on text content\n",
    "    \n",
    "    {image_context}\n",
    "    \n",
    "    Format:\n",
    "    MCQ: Question? (A) Option1 (B) Option2 (C) Option3 (D) Option4 | Answer: X\n",
    "    MCQ: [IMAGE QUESTION] Question? (A) Option1 (B) Option2 (C) Option3 (D) Option4 | Answer: X\n",
    "    Short Answer (2 marks): Question?\n",
    "    Short Answer (2 marks): [IMAGE QUESTION] Question?\n",
    "    Long Answer (5 marks): Question?\n",
    "    Long Answer (5 marks): [IMAGE QUESTION] Question?\n",
    "    Case-Based: Case description followed by questions\n",
    "    Case-Based: [IMAGE QUESTION] Case description followed by questions\n",
    "    \n",
    "    For chemical equations, write them in plain text format (like \"2H2 + O2 → 2H2O\") not LaTeX format.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"deepseek/deepseek-r1:free\",\n",
    "            messages=[{\"role\": \"user\", \"content\": f\"{prompt}\\n\\nContent: {chapter_text}\"}],\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        # Convert any LaTeX equations to normal format\n",
    "        questions = completion.choices[0].message.content.strip().split(\"\\n\")\n",
    "        normalized_questions = []\n",
    "        \n",
    "        for q in questions:\n",
    "            # Convert LaTeX equations to normal text\n",
    "            q = re.sub(r'\\\\\\((.*?)\\\\\\)', lambda m: m.group(1).replace('\\\\text{', '').replace('}', '').replace('\\\\', '').replace('_', ''), q)\n",
    "            q = re.sub(r'\\\\left\\((.*?)\\\\right\\)', r'(\\1)', q)\n",
    "            q = re.sub(r'\\\\rightarrow', r'→', q)\n",
    "            normalized_questions.append(q)\n",
    "        \n",
    "        return normalized_questions\n",
    "    except Exception as e:\n",
    "        return [f\"Question generation failed: {e}\"]   \n",
    "\n",
    "def extract_questions(text):\n",
    "    \"\"\"Extract questions only from the EXERCISES section\"\"\"\n",
    "    exercises_pattern = r\"E\\s*X\\s*E\\s*R\\s*C\\s*I\\s*S\\s*E\\s*S(.*?)(?=\\d+\\s+CHAPTER|\\Z)\"\n",
    "    matches = re.findall(exercises_pattern, text, re.DOTALL)\n",
    "    \n",
    "    questions = []\n",
    "    for match in matches:\n",
    "        exercises_section = match.strip()\n",
    "        question_pattern = r\"(\\d+\\.\\s)(.*?)(?=\\d+\\.\\s|\\Z)\"\n",
    "        question_matches = re.findall(question_pattern, exercises_section)\n",
    "        questions.extend([q[1].strip() for q in question_matches])\n",
    "    \n",
    "    return questions\n",
    "\n",
    "def deepseek_answer(question, context, chapter_images=None):\n",
    "    \n",
    "    context_with_images = context\n",
    "    if chapter_images and len(chapter_images) > 0:\n",
    "        image_mentions = []\n",
    "        for i, img_data in enumerate(chapter_images):\n",
    "            if img_data.get('caption'):\n",
    "                # Check if the question might be asking about figures\n",
    "                if re.search(r'(figure|diagram|image|graph|chart|picture|plot|illustration)', \n",
    "                            question, re.IGNORECASE):\n",
    "                    image_mentions.append(f\"Figure {i+1}: {img_data['caption']}\")\n",
    "        \n",
    "        if image_mentions:\n",
    "            context_with_images += \"\\n\\nRelevant Figures in the chapter:\\n\" + \"\\n\".join(image_mentions)\n",
    "    \n",
    "    max_retries = 5\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"deepseek/deepseek-r1:free\",\n",
    "                messages=[{\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": f\"\"\"Answer this question in 2-3 sentences maximum. Just provide the direct answer without ANY reasoning process.\n",
    "DO NOT write phrases like \\\"Based on the context\\\", \\\"the answer is\\\", etc.\n",
    "DO NOT include any thinking process.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Context from textbook: {context_with_images}\"\"\"\n",
    "                }],\n",
    "                temperature=0.3\n",
    "            )\n",
    "            answer = completion.choices[0].message.content.strip() if completion.choices else None\n",
    "            \n",
    "            if answer:\n",
    "                answer = re.sub(r'^(Okay|Alright|Let me|Based on|Looking at|If we|To solve|In this|So|Now,|Well,|The question|From the|First,).*?[.!?]\\s*', '', answer).strip()\n",
    "                answer = re.sub(r'(The answer is|This means that|Thus|Therefore|Hence|So,|To summarize|In conclusion)[,:](.*?)$', r'\\2', answer).strip()\n",
    "                answer = re.sub(r'I (need to|will|should|can).*?[.!?]\\s*', '', answer).strip()\n",
    "                answer = re.sub(r'Let\\'s.*?[.!?]\\s*', '', answer).strip()\n",
    "                answer = re.sub(r'Wait.*?[.!?]\\s*', '', answer).strip()\n",
    "                answer = re.sub(r'Hmm.*?[.!?]\\s*', '', answer).strip()\n",
    "                \n",
    "                return answer\n",
    "            \n",
    "            time.sleep(1)\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt+1} failed: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2)\n",
    "    \n",
    "    return \"This question requires further review.\"\n",
    "\n",
    "def add_image_to_document(doc, image, caption=None, width=4.5):\n",
    "    \"\"\"Add an image to the Word document with optional caption\"\"\"\n",
    "    try:\n",
    "        \n",
    "        img_byte_arr = BytesIO()\n",
    "        image.save(img_byte_arr, format='PNG')\n",
    "        img_byte_arr.seek(0)\n",
    "        \n",
    "       \n",
    "        doc.add_picture(img_byte_arr, width=Inches(width))\n",
    "        \n",
    "        \n",
    "        if caption:\n",
    "            caption_para = doc.add_paragraph(caption)\n",
    "            caption_para.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "            caption_para.style = 'Caption'\n",
    "        \n",
    "        \n",
    "        doc.add_paragraph()\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error adding image to document: {e}\")\n",
    "        return False\n",
    "\n",
    "def format_text_with_bold(text):\n",
    "    \"\"\"Format text with bold for content between ** **\"\"\"\n",
    "    \n",
    "    bold_pattern = r'\\*\\*(.*?)\\*\\*'\n",
    "    matches = re.findall(bold_pattern, text)\n",
    "    \n",
    "    \n",
    "    for match in matches:\n",
    "        text = text.replace(f\"**{match}**\", match)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def save_summary(summary_dict, images_dict, output_path=\"Summary.docx\"):\n",
    "    doc = Document()\n",
    "    doc.add_heading(\"Chapter Summaries\", level=1)\n",
    "\n",
    "    for chapter, summary_text in summary_dict.items():\n",
    "        \n",
    "        if summary_text.startswith(\"**CHAPTER\"):\n",
    "            \n",
    "            chapter_title = summary_text.split(\"\\n\")[0].replace(\"**\", \"\")\n",
    "            doc.add_heading(chapter_title, level=2)\n",
    "            \n",
    "            \n",
    "            summary_content = \"\\n\".join(summary_text.split(\"\\n\")[2:])\n",
    "            \n",
    "            \n",
    "            for paragraph in summary_content.split(\"\\n\\n\"):\n",
    "                if paragraph.strip():\n",
    "                    # Format the text - make content between ** ** bold\n",
    "                    formatted_para = format_text_with_bold(paragraph.strip())\n",
    "                    para = doc.add_paragraph()\n",
    "                    \n",
    "                    \n",
    "                    bold_pattern = r'\\*\\*(.*?)\\*\\*'\n",
    "                    parts = re.split(bold_pattern, formatted_para)\n",
    "                    \n",
    "                    for i, part in enumerate(parts):\n",
    "                        \n",
    "                        if i % 2 == 0:\n",
    "                            para.add_run(part)\n",
    "                        else:\n",
    "                            para.add_run(part).bold = True\n",
    "            \n",
    "            \n",
    "            chapter_images = images_dict.get(chapter, [])\n",
    "            for img_data in chapter_images:\n",
    "                add_image_to_document(doc, img_data['image'], img_data['caption'])\n",
    "        else:\n",
    "            \n",
    "            doc.add_paragraph(summary_text)\n",
    "\n",
    "    doc.save(output_path)\n",
    "    return output_path\n",
    "\n",
    "\n",
    "def save_questions(questions_dict, images_dict, output_path=\"Questions.docx\"):\n",
    "    doc = Document()\n",
    "    doc.add_heading(\"Generated Questions\", level=1)\n",
    "    \n",
    "    for chapter, questions in questions_dict.items():\n",
    "        doc.add_heading(f\"Chapter {chapter}\", level=2)\n",
    "        \n",
    "        \n",
    "        image_references = set()\n",
    "        for question in questions:\n",
    "            \n",
    "            matches = re.findall(r'\\bImage\\s+(\\d+)\\b', question, re.IGNORECASE)\n",
    "            matches.extend(re.findall(r'\\[IMAGE\\s+(\\d+)\\]', question, re.IGNORECASE))\n",
    "            matches.extend(re.findall(r'\\[IMAGE QUESTION\\]', question, re.IGNORECASE))\n",
    "            \n",
    "            \n",
    "            for match in matches:\n",
    "                if match.isdigit():\n",
    "                    image_references.add(int(match))\n",
    "                else:\n",
    "                    # For general [IMAGE QUESTION] tags, include all images\n",
    "                    image_references.update(range(1, len(images_dict.get(chapter, [])) + 1))\n",
    "        \n",
    "        \n",
    "        chapter_images = images_dict.get(chapter, [])\n",
    "        if chapter_images:\n",
    "            doc.add_paragraph(\"Chapter Visual References:\")\n",
    "            \n",
    "            \n",
    "            for i, img_data in enumerate(chapter_images):\n",
    "                \n",
    "                if (i+1) in image_references or not image_references:\n",
    "                    doc.add_paragraph(f\"Image {i+1}:\")\n",
    "                    add_image_to_document(doc, img_data['image'], img_data['caption'])\n",
    "        \n",
    "       \n",
    "        doc.add_heading(\"Questions\", level=3)\n",
    "        for question in questions:\n",
    "            if not question.strip():\n",
    "                continue\n",
    "                \n",
    "            \n",
    "            question = re.sub(r'\\\\\\((.*?)\\\\\\)', lambda m: m.group(1).replace('\\\\text{', '').replace('}', '').replace('\\\\', '').replace('_', ''), question)\n",
    "            question = re.sub(r'\\\\left\\((.*?)\\\\right\\)', r'(\\1)', question)\n",
    "            question = re.sub(r'\\\\rightarrow', r'→', question)\n",
    "            \n",
    "            \n",
    "            paragraph = doc.add_paragraph()\n",
    "            \n",
    "            \n",
    "            if question.strip().startswith('-'):\n",
    "                # Replace with bullet\n",
    "                question = \"•\" + question[1:]\n",
    "            \n",
    "            \n",
    "            if '**' in question:\n",
    "                \n",
    "                parts = re.split(r'(\\*\\*.*?\\*\\*)', question)\n",
    "                for part in parts:\n",
    "                    if part.startswith('**') and part.endswith('**'):\n",
    "                        \n",
    "                        bold_text = part[2:-2]\n",
    "                        paragraph.add_run(bold_text).bold = True\n",
    "                    else:\n",
    "                        \n",
    "                        paragraph.add_run(part)\n",
    "            else:\n",
    "                \n",
    "                paragraph.add_run(question)\n",
    "            \n",
    "            \n",
    "            doc.add_paragraph()\n",
    "    \n",
    "    doc.save(output_path)\n",
    "    return output_path         \n",
    "        \n",
    "\n",
    "def save_qa(chapter_dict, qa_dict, images_dict, output_path=\"NCERT_Questions_Answers.docx\"):\n",
    "    doc = Document()\n",
    "    doc.add_heading(\"NCERT Questions and Answers\", level=1)\n",
    "\n",
    "    for chapter, content in chapter_dict.items():\n",
    "        doc.add_page_break()\n",
    "        doc.add_heading(f\"Chapter {chapter}\", level=2)\n",
    "        \n",
    "        \n",
    "        chapter_images = images_dict.get(chapter, [])\n",
    "\n",
    "        for i, question in enumerate(qa_dict.get(chapter, [])):\n",
    "            \n",
    "            is_image_question = False\n",
    "            relevant_image = None\n",
    "            \n",
    "            if chapter_images and re.search(r'(figure|diagram|image|graph|chart|picture|plot|illustration)', \n",
    "                                          question, re.IGNORECASE):\n",
    "                is_image_question = True\n",
    "                \n",
    "                for img_data in chapter_images:\n",
    "                    if img_data.get('caption') and any(word in img_data['caption'].lower() \n",
    "                                                     for word in question.lower().split()):\n",
    "                        relevant_image = img_data\n",
    "                        break\n",
    "                \n",
    "                if not relevant_image and chapter_images:\n",
    "                    relevant_image = chapter_images[0]  \n",
    "            \n",
    "           \n",
    "            question_para = doc.add_paragraph()\n",
    "            question_para.add_run(\"Q: \").bold = True\n",
    "            \n",
    "            \n",
    "            if '**' in question:\n",
    "                parts = re.split(r'(\\*\\*.*?\\*\\*)', question)\n",
    "                for part in parts:\n",
    "                    if part.startswith('**') and part.endswith('**'):\n",
    "                        # Bold text\n",
    "                        bold_text = part[2:-2]\n",
    "                        question_para.add_run(bold_text).bold = True\n",
    "                    else:\n",
    "                        \n",
    "                        question_para.add_run(part)\n",
    "            else:\n",
    "                question_para.add_run(question)\n",
    "            \n",
    "            \n",
    "            if is_image_question and relevant_image:\n",
    "                add_image_to_document(doc, relevant_image['image'], width=3.5)\n",
    "            \n",
    "            \n",
    "            answer = deepseek_answer(question, content, chapter_images)\n",
    "            \n",
    "            \n",
    "            answer = re.sub(r'\\\\\\((.*?)\\\\\\)', lambda m: m.group(1).replace('\\\\text{', '').replace('}', '').replace('\\\\', '').replace('_', ''), answer)\n",
    "            \n",
    "            answer_para = doc.add_paragraph()\n",
    "            answer_para.add_run(\"A: \").bold = True\n",
    "            \n",
    "            \n",
    "            if '**' in answer:\n",
    "                parts = re.split(r'(\\*\\*.*?\\*\\*)', answer)\n",
    "                for part in parts:\n",
    "                    if part.startswith('**') and part.endswith('**'):\n",
    "                        # Bold text\n",
    "                        bold_text = part[2:-2]\n",
    "                        answer_para.add_run(bold_text).bold = True\n",
    "                    else:\n",
    "                        # Normal text\n",
    "                        answer_para.add_run(part)\n",
    "            else:\n",
    "                answer_para.add_run(answer)\n",
    "            \n",
    "            if i < len(qa_dict.get(chapter, [])) - 1:\n",
    "                doc.add_paragraph(\"\")\n",
    "    \n",
    "    doc.save(output_path)\n",
    "    return output_path\n",
    "\n",
    "def match_figures_to_chapters(figures, chapters):\n",
    "    \"\"\"Match figures to chapters based on text content\"\"\"\n",
    "    chapter_images = {chapter: [] for chapter in chapters.keys()}\n",
    "    \n",
    "    \n",
    "    print(\"Analyzing figures and matching to chapters...\")\n",
    "    for img_data in figures:\n",
    "        try:\n",
    "            \n",
    "            description = analyze_image_with_qwen(img_data['image'])\n",
    "            \n",
    "          \n",
    "            if img_data['caption']:\n",
    "                full_caption = f\"{img_data['caption']} - {description}\"\n",
    "            else:\n",
    "                full_caption = description\n",
    "                \n",
    "            img_data['caption'] = full_caption\n",
    "            \n",
    "            \n",
    "            best_chapter = None\n",
    "            highest_score = 0\n",
    "            \n",
    "            \n",
    "            desc_words = set(re.findall(r'\\b\\w+\\b', description.lower()))\n",
    "            \n",
    "            for chapter, content in chapters.items():\n",
    "                \n",
    "                chapter_sample = content[:5000].lower()\n",
    "                \n",
    "                \n",
    "                match_score = sum(1 for word in desc_words if word in chapter_sample and len(word) > 3)\n",
    "                \n",
    "                if match_score > highest_score:\n",
    "                    highest_score = match_score\n",
    "                    best_chapter = chapter\n",
    "            \n",
    "            \n",
    "            if best_chapter:\n",
    "                chapter_images[best_chapter].append(img_data)\n",
    "            else:\n",
    "                \n",
    "                first_chapter = list(chapters.keys())[0] if chapters else None\n",
    "                if first_chapter:\n",
    "                    chapter_images[first_chapter].append(img_data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing figure {img_data.get('filename', 'unknown')}: {e}\")\n",
    "    \n",
    "    return chapter_images\n",
    "\n",
    "def process_files(pdf_files, figures_folder, output_dir=\"./output\", generate_summary=True, \n",
    "                 generate_questions=True, generate_qa=True):\n",
    "    \"\"\"Process PDF files and figures folder\"\"\"\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    \n",
    "    output_files = []\n",
    "    all_chapters = {}\n",
    "    all_qa_chapters = {}\n",
    "    all_questions = {}\n",
    "    \n",
    "   \n",
    "    all_figures = load_figures_from_folder(figures_folder)\n",
    "    \n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        \n",
    "        futures = []\n",
    "        for pdf_file in pdf_files:\n",
    "            future = executor.submit(extract_text_from_pdf, pdf_file)\n",
    "            futures.append(future)\n",
    "        \n",
    "        \n",
    "        for future in futures:\n",
    "            text = future.result()\n",
    "            \n",
    "            \n",
    "            if generate_summary or generate_questions:\n",
    "                chapters = extract_chapters(text, for_qa=False)\n",
    "                all_chapters.update(chapters)\n",
    "            \n",
    "            if generate_qa:\n",
    "                qa_chapters = extract_chapters(text, for_qa=True)\n",
    "                for chapter, content in qa_chapters.items():\n",
    "                    questions = extract_questions(content)\n",
    "                    all_questions[chapter] = questions\n",
    "                    all_qa_chapters[chapter] = content\n",
    "    \n",
    "    \n",
    "    chapter_figures = match_figures_to_chapters(all_figures, all_chapters)\n",
    "    \n",
    "    \n",
    "    if generate_summary:\n",
    "        summary_results = {}\n",
    "        processed_images = {}\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "            \n",
    "            future_to_chapter = {\n",
    "                executor.submit(summarize_chapter, chapter, content, chapter_figures.get(chapter, [])): chapter\n",
    "                for chapter, content in all_chapters.items()\n",
    "            }\n",
    "            \n",
    "            \n",
    "            for future in future_to_chapter:\n",
    "                chapter = future_to_chapter[future]\n",
    "                summary_text, chapter_processed_images = future.result()\n",
    "                summary_results[chapter] = summary_text\n",
    "                processed_images[chapter] = chapter_processed_images\n",
    "\n",
    "        \n",
    "        summary_path = os.path.join(output_dir, \"Summary.docx\")\n",
    "        save_summary(summary_results, processed_images, summary_path)\n",
    "        output_files.append(summary_path)\n",
    "    \n",
    "  \n",
    "    if generate_questions:\n",
    "        questions_dict = {}\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "           \n",
    "            future_to_chapter = {\n",
    "                executor.submit(generate_sample_questions, \n",
    "                               content, \n",
    "                               chapter_figures.get(chapter, [])): chapter\n",
    "                for chapter, content in all_chapters.items()\n",
    "            }\n",
    "            \n",
    "            \n",
    "            for future in future_to_chapter:\n",
    "                chapter = future_to_chapter[future]\n",
    "                questions_dict[chapter] = future.result()\n",
    "\n",
    "        \n",
    "        questions_path = os.path.join(output_dir, \"Questions.docx\")\n",
    "        save_questions(questions_dict, chapter_figures, questions_path)\n",
    "        output_files.append(questions_path)\n",
    "    \n",
    "    \n",
    "    if generate_qa:\n",
    "        qa_path = os.path.join(output_dir, \"NCERT_Questions_Answers.docx\")\n",
    "        save_qa(all_qa_chapters, all_questions, chapter_figures, qa_path)\n",
    "        output_files.append(qa_path)\n",
    "    \n",
    "    return output_files\n",
    "\n",
    "def main(pdf_files_paths, figures_folder, output_dir=None):\n",
    "    \"\"\"Main function to process PDF files and figures\"\"\"\n",
    "    if output_dir is None:\n",
    "        \n",
    "        if os.path.exists('/kaggle/working'):\n",
    "            output_dir = '/kaggle/working'\n",
    "        else:\n",
    "            output_dir = './output'\n",
    "\n",
    "    print(f\"Processing {len(pdf_files_paths)} PDF files with figures from {figures_folder}...\")\n",
    "    output_files = process_files(\n",
    "        pdf_files_paths,\n",
    "        figures_folder,\n",
    "        output_dir=output_dir,\n",
    "        generate_summary=False,\n",
    "        generate_questions=True, \n",
    "        generate_qa=False\n",
    "    )\n",
    "    \n",
    "    print(f\"Processing complete. Output files saved to: {output_dir}\")\n",
    "    for file in output_files:\n",
    "        print(f\" - {os.path.basename(file)}\")\n",
    "    \n",
    "    return output_files\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    pdf_files = [\"/kaggle/input/books-pdf/Books/jesc110.pdf\"]\n",
    "    figures_folder = \"/kaggle/input/d/smritikc/figure/Figure10\"  \n",
    "    \n",
    "    \n",
    "    output_directory = '/kaggle/working' if os.path.exists('/kaggle/working') else './output'\n",
    "    main(pdf_files, figures_folder, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6614100,
     "sourceId": 10677399,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6781767,
     "sourceId": 10909988,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6781773,
     "sourceId": 10909994,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
